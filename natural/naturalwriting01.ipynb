{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3011cea-9fff-4652-8966-97107bf43c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2paragraphs(filename, min_size=1):\n",
    "    \"\"\" A text contained in the file 'filename' will be read \n",
    "    and chopped into paragraphs.\n",
    "    Paragraphs with a string length less than min_size will be ignored.\n",
    "    A list of paragraph strings will be returned\"\"\"\n",
    "    \n",
    "    txt = open(filename).read()\n",
    "    paragraphs = [para for para in txt.split(\"\\n\\n\") if len(para) > min_size]\n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad384b1b-8098-4d17-a9d3-4d48689d8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the position of lables is very important\n",
    "# it corresponds to a novel by that author within \"files\"\n",
    "# the position of the author is also relevant, as it will correspond to metrics\n",
    "# i.e. Samuel Butler's metrics are always returned in position 1\n",
    "labels = ['Virginia Woolf', 'Samuel Butler', 'Herman Melville', \n",
    "          'David Herbert Lawrence', 'Daniel Defoe', 'James Joyce']\n",
    "\n",
    "\n",
    "# names of books we have to train our machine model\n",
    "files = ['night_and_day_virginia_woolf.txt', 'the_way_of_all_flash_butler.txt',\n",
    "         'moby_dick_melville.txt', 'sons_and_lovers_lawrence.txt',\n",
    "         'robinson_crusoe_defoe.txt', 'james_joyce_ulysses.txt']\n",
    "\n",
    "# location of our books\n",
    "path = \"books/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c2e57b-df95-4fd4-bea9-8923b921d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "targets = []\n",
    "counter = 0\n",
    "\n",
    "# loop across all files we have downloaded\n",
    "for fname in files:\n",
    "    paras = text2paragraphs(path + fname, min_size=150) # return a book with paragraphs over 150 chars in a list\n",
    "    data.extend(paras)\n",
    "    targets += [counter] * len(paras)\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "175a8367-60ec-46a2-9df4-d1af8653322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell is useless, because train_test_split will do the shuffling!\n",
    "\n",
    "import random\n",
    "\n",
    "data_targets = list(zip(data, targets))\n",
    "# create random permutation on list:\n",
    "data_targets = random.sample(data_targets, len(data_targets))\n",
    "\n",
    "data, targets = list(zip(*data_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86983d35-8905-42d8-b668-e9c5f486d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "res = train_test_split(data, targets, \n",
    "                       train_size=0.8,\n",
    "                       test_size=0.2,\n",
    "                       random_state=42)\n",
    "train_data, test_data, train_targets, test_targets = res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ba6baf-a454-437c-9ebc-0c393b1389cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.914534567229178\n",
      "F1-score:  0.9109966569226192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "vectors = vectorizer.fit_transform(train_data)\n",
    "\n",
    "# creating a classifier\n",
    "classifier = MultinomialNB(alpha=.01)\n",
    "classifier.fit(vectors, train_targets)\n",
    "\n",
    "vectors_test = vectorizer.transform(test_data)\n",
    "\n",
    "predictions = classifier.predict(vectors_test)\n",
    "accuracy_score = metrics.accuracy_score(test_targets, \n",
    "                                        predictions)\n",
    "f1_score = metrics.f1_score(test_targets, \n",
    "                            predictions, \n",
    "                            average='macro')\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score)\n",
    "print(\"F1-score: \", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48eb24d-490f-4394-86ab-5a54eff67676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
